{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "강화학습과 게임1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chan0226/Reinforcement-learning-game/blob/main/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%EA%B3%BC_%EA%B2%8C%EC%9E%841.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bLMWMbJxMLA"
      },
      "source": [
        "## 다중손잡이 밴딧 문제 - [ 행동 - 보상] 사이클"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMbWw23-xNta"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE24T15tzxCt"
      },
      "source": [
        "# 이문제는 확율을 모르면서 매 게임을 할때 얻는 이익을 보고 최대한 이익을 찾을수 있는 방향을...\n",
        "# 이 알고리즘의 정보는 행동에 대한 보상(1 -1)\n",
        "# 밴딩머신의 손잡이 승률\n",
        "arms_profit = [0.4,0.12,0.52,0.6,0.25]\n",
        "n_arms = len(arms_profit)\n",
        "\n",
        "#손잡이를 당기는 횟수 ( 에피소드의 길이)  문제의 시작과 끝까지 도달하는데 시도하는 횟수 또는 합습횟수\n",
        "n_trial = 10000\n",
        "\n",
        "#handle : 손잡이 번호(게임기 번호)\n",
        "def pull_banit(handle):\n",
        "  q = np.random.random()\n",
        "  if q < arms_profit[handle]:  \n",
        "    return 1\n",
        "  else:\n",
        "    return -1  \n",
        "\n",
        "# 랜덤정책을 모방하는 함수\n",
        "def random_exploration():\n",
        "  espisode=[]\n",
        "  num = np.zeros(n_arms)    # 손잡이별로 당긴 횟수\n",
        "  wins  = np.zeros(n_arms)  # 손잡이별로 이긴 횟수\n",
        "  for i in range(n_trial):\n",
        "    h = np.random.randint(0,n_arms) # 무작위로 손잡이를 선택\n",
        "    reward = pull_banit(h)\n",
        "    espisode.append([h,reward])\n",
        "    num[h] += 1\n",
        "    wins[h] +=1 if reward == 1 else 0 \n",
        "  return espisode,(num,wins)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3StUjTx4ybE",
        "outputId": "304551e0-266d-4e29-e4c2-cda3856b6f0c"
      },
      "source": [
        "e,r =  random_exploration()\n",
        "# 손잡이별 승리확율\n",
        "# 이긴횟수 / 총 시도 횟수    win /  num     r[1] / r[0]\n",
        "\n",
        "# 아래 결과의 백터가 프로그램이 찾은 최적의 정책\n",
        "print('손잡이별 승리 확율 : ', ['%.4f' % (r[1][i] / r[0][i]) for i in range(n_arms)] )\n",
        "\n",
        "# 손잡이별 수익\n",
        "# r[0][i] - r[1][i] for i in range(n_arms)\n",
        "print('손잡이별 수익($) : ', ['%d' % (2*r[1][i] - r[0][i]) for i in range(n_arms)] )\n",
        "print('순수익 :',sum(np.asarray(e)[:,1]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "손잡이별 승리 확율 :  ['0.3906', '0.1177', '0.5302', '0.5882', '0.2582']\n",
            "손잡이별 수익($) :  ['-438', '-1552', '120', '360', '-940']\n",
            "순수익 : -2450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lJ-rehm8Kkr"
      },
      "source": [
        "# 최초 설정한 확율과 arms_profit = [0.4,0.12,0.52,0.6,0.25] 와 결과가 비슷\n",
        "# [0,0,0,1,0] --> 확율을 몰아준 최적의 정책"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55bq_-Ap-RiR"
      },
      "source": [
        "# 입실론 탐욕 알고리즘\n",
        "def epsilon_greedy(eps):\n",
        "  episode = []\n",
        "  num = np.zeros(n_arms) # 손잡이 당긴 횟수\n",
        "  wins = np.zeros(n_arms) # 손잡이 별로 이긴 횟수\n",
        "  for i in range(n_trial):\n",
        "    r = np.random.random()  # 랜덤방식 -- 탐험형의 기본..\n",
        "    if(r < eps or sum(wins) == 0 ):           # 탐험형 \n",
        "      h = np.random.randint(0,n_arms)     # 임의의 핸들(게임기)\n",
        "    else:                                     # 탐사형   높은 확율을 보이는 경우만 계속 시도하는 --> 보완... 일정비율을 추가해서 탐험형도 시도\n",
        "      prob = np.asarray([wins[i] / num[i]  if num[i] > 0 else 0.0 for i in range(n_arms)])\n",
        "      prob = prob / sum(prob)\n",
        "      h = np.random.choice(range(n_arms),p=prob)\n",
        "    reward = pull_banit(h)\n",
        "    episode.append([h,reward])\n",
        "    num[h] += 1\n",
        "    wins[h] += 1 if reward == 1 else 0\n",
        "  return episode, (num,wins)     \n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k9kqdKCGURw",
        "outputId": "9c00d7b6-d022-448d-dca3-682e932f4f05"
      },
      "source": [
        "e,r = epsilon_greedy(0.1)\n",
        "print('손잡이별 승리 확율 : ', ['%.4f' % (r[1][i] / r[0][i]) for i in range(n_arms)] )\n",
        "print('손잡이별 수익($) : ', ['%d' % (2*r[1][i] - r[0][i]) for i in range(n_arms)] )\n",
        "print('순수익 :',sum(np.asarray(e)[:,1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "손잡이별 승리 확율 :  ['0.3886', '0.1160', '0.5225', '0.5957', '0.2347']\n",
            "손잡이별 수익($) :  ['-451', '-510', '129', '585', '-737']\n",
            "순수익 : -984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nfgQat7ID4f"
      },
      "source": [
        "# 탐욕 알고리즘  - 보완예정\n",
        "def greedy():\n",
        "  episode = []\n",
        "  num = np.zeros(n_arms) # 손잡이 당긴 횟수\n",
        "  wins = np.zeros(n_arms) # 손잡이 별로 이긴 횟수\n",
        "  for i in range(n_trial):\n",
        "    r = np.random.random()  # 랜덤방식 -- 탐험형의 기본..\n",
        "    if(sum(wins) == 0 ):           \n",
        "      h = np.random.randint(0,n_arms)     # 임의의 핸들(게임기)\n",
        "    else:                                     # 탐사형   높은 확율을 보이는 경우만 계속 시도하는 --> 보완... 일정비율을 추가해서 탐험형도 시도\n",
        "      prob = np.asarray([wins[i] / num[i]  if num[i] > 0 else 0.0 for i in range(n_arms)])\n",
        "      prob = prob / sum(prob)\n",
        "      h = np.random.choice(range(n_arms),p=prob)\n",
        "    reward = pull_banit(h)\n",
        "    episode.append([h,reward])\n",
        "    num[h] += 1\n",
        "    wins[h] += 1 if reward == 1 else 0\n",
        "  return episode, (num,wins)     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjRBncNxIQKP",
        "outputId": "4ad9c51c-3a6b-4683-be46-f1b0e045b04e"
      },
      "source": [
        "e,r = greedy()\n",
        "print('손잡이별 승리 확율 : ', ['%.4f' % (r[1][i] / r[0][i]) for i in range(n_arms)] )\n",
        "print('손잡이별 수익($) : ', ['%d' % (2*r[1][i] - r[0][i]) for i in range(n_arms)] )\n",
        "print('순수익 :',sum(np.asarray(e)[:,1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "손잡이별 승리 확율 :  ['0.0000', '0.0000', '0.5293', '0.0000', 'nan']\n",
            "손잡이별 수익($) :  ['-1', '-2', '586', '-1', '0']\n",
            "순수익 : 582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ]
        }
      ]
    }
  ]
}